{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting data from yann lecunn dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yann Lecunn dataset is of the format idx and split across 4 files \n",
    "1. train-images.idx3-ubyte : training image set which consists of 60000 images each image is represented by a 28*28 array\n",
    "2. train-labels.idx1-ubyte : training label set which consists of 60000 labels \n",
    "3. t10k-images.idx3-ubyte : test image set which consists of 10000 images each image is represented by a 28*28\n",
    "4. t10k-labels.idx1-ubyte : training label set which consists of 10000 labels\n",
    "\n",
    "Get the dataset from http://yann.lecun.com/exdb/mnist/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import idx2numpy\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_3D = idx2numpy.convert_from_file('/root/decision-tree-python/train-images.idx3-ubyte')\n",
    "X_train = X_train_3D.flatten().reshape(60000,784)\n",
    "\n",
    "y_train = idx2numpy.convert_from_file('/root/decision-tree-python/train-labels.idx1-ubyte')\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 784), (10000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_3D = idx2numpy.convert_from_file('/root/decision-tree-python/t10k-images.idx3-ubyte')\n",
    "X_test =  X_test_3D.flatten().reshape(10000,784)\n",
    "\n",
    "y_test = idx2numpy.convert_from_file('/root/decision-tree-python/t10k-labels.idx1-ubyte')\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=8)\n",
      "Number of nodes in the decision tree 505.\n",
      "Number of threshold in the decision tree 505.\n",
      "Number of leaves in the decision tree 253.\n",
      "0.8167 0.82926\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "X_shuffle,y_shuffle = shuffle(X_train,y_train)\n",
    "X_train = X_shuffle[0:50000]\n",
    "y_train = y_shuffle[0:50000]\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "#dt_clf = tree.DecisionTreeClassifier(max_depth=20, max_leaf_nodes=300)\n",
    "#dt_clf = tree.DecisionTreeClassifier(max_depth=4, max_leaf_nodes=20)\n",
    "dt_clf = tree.DecisionTreeClassifier(max_depth=8)\n",
    "\n",
    "#y_train_pred = cross_val_predict(dt_clf, X_train, y_train, cv=2)\n",
    "print(dt_clf.fit(X_train, y_train))\n",
    "\n",
    "print('Number of nodes in the decision tree {}.'.format(dt_clf.tree_.node_count))\n",
    "print('Number of threshold in the decision tree {}.'.format(len(dt_clf.tree_.threshold)))\n",
    "print('Number of leaves in the decision tree {}.'.format(dt_clf.tree_.n_leaves))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, dt_clf.predict(X_test)), accuracy_score(y_train, dt_clf.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max and Min values of thresholds in decision tree are 251 -2\n"
     ]
    }
   ],
   "source": [
    "threshold = dt_clf.tree_.threshold\n",
    "import pandas as pd\n",
    "df_train = pd.DataFrame(data = X_train, columns = range(X_train[0].shape[0]))\n",
    "df_test = pd.DataFrame(data = X_test, columns = range(X_test[0].shape[0]))\n",
    "df_train.shape, df_test.shape\n",
    "df = pd.concat([df_train, df_test])\n",
    "unique_vals = []\n",
    "for i in df.columns:\n",
    "    unique_vals.append(df[i].unique())\n",
    "flatten_list = np.concatenate(unique_vals).ravel()\n",
    "print('Max and Min values of thresholds in decision tree are', max([int(i) for i in list(set(threshold))]), min([int(i) for i in list(set(threshold))]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Displaying the tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- feature_350 <= 141.50\n",
      "|   |--- feature_568 <= 0.50\n",
      "|   |   |--- feature_430 <= 0.50\n",
      "|   |   |   |--- feature_405 <= 0.50\n",
      "|   |   |   |   |--- feature_484 <= 39.50\n",
      "|   |   |   |   |   |--- feature_154 <= 1.00\n",
      "|   |   |   |   |   |   |--- feature_594 <= 6.50\n",
      "|   |   |   |   |   |   |   |--- feature_157 <= 1.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |   |--- feature_157 >  1.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_594 >  6.50\n",
      "|   |   |   |   |   |   |   |--- feature_481 <= 28.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_481 >  28.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_154 >  1.00\n",
      "|   |   |   |   |   |   |--- feature_509 <= 22.50\n",
      "|   |   |   |   |   |   |   |--- feature_571 <= 9.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_571 >  9.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_509 >  22.50\n",
      "|   |   |   |   |   |   |   |--- feature_350 <= 3.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_350 >  3.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |--- feature_484 >  39.50\n",
      "|   |   |   |   |   |--- feature_211 <= 53.50\n",
      "|   |   |   |   |   |   |--- feature_487 <= 153.00\n",
      "|   |   |   |   |   |   |   |--- feature_543 <= 179.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |   |--- feature_543 >  179.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |--- feature_487 >  153.00\n",
      "|   |   |   |   |   |   |   |--- feature_399 <= 4.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_399 >  4.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |--- feature_211 >  53.50\n",
      "|   |   |   |   |   |   |--- feature_437 <= 1.00\n",
      "|   |   |   |   |   |   |   |--- feature_386 <= 2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_386 >  2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_437 >  1.00\n",
      "|   |   |   |   |   |   |   |--- feature_427 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |   |--- feature_427 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |--- feature_405 >  0.50\n",
      "|   |   |   |   |--- feature_516 <= 0.50\n",
      "|   |   |   |   |   |--- feature_353 <= 2.50\n",
      "|   |   |   |   |   |   |--- feature_322 <= 10.00\n",
      "|   |   |   |   |   |   |   |--- feature_355 <= 12.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_355 >  12.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |--- feature_322 >  10.00\n",
      "|   |   |   |   |   |   |   |--- feature_546 <= 38.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_546 >  38.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_353 >  2.50\n",
      "|   |   |   |   |   |   |--- feature_346 <= 1.00\n",
      "|   |   |   |   |   |   |   |--- feature_652 <= 59.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_652 >  59.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- feature_346 >  1.00\n",
      "|   |   |   |   |   |   |   |--- feature_210 <= 6.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |   |--- feature_210 >  6.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |--- feature_516 >  0.50\n",
      "|   |   |   |   |   |--- feature_376 <= 16.50\n",
      "|   |   |   |   |   |   |--- feature_208 <= 1.00\n",
      "|   |   |   |   |   |   |   |--- feature_289 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_289 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |--- feature_208 >  1.00\n",
      "|   |   |   |   |   |   |   |--- feature_710 <= 15.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_710 >  15.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |--- feature_376 >  16.50\n",
      "|   |   |   |   |   |   |--- feature_658 <= 1.50\n",
      "|   |   |   |   |   |   |   |--- feature_459 <= 14.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |   |--- feature_459 >  14.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |--- feature_658 >  1.50\n",
      "|   |   |   |   |   |   |   |--- feature_434 <= 85.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_434 >  85.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |--- feature_430 >  0.50\n",
      "|   |   |   |--- feature_211 <= 28.50\n",
      "|   |   |   |   |--- feature_98 <= 0.50\n",
      "|   |   |   |   |   |--- feature_267 <= 121.50\n",
      "|   |   |   |   |   |   |--- feature_95 <= 7.00\n",
      "|   |   |   |   |   |   |   |--- feature_155 <= 78.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |   |--- feature_155 >  78.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |--- feature_95 >  7.00\n",
      "|   |   |   |   |   |   |   |--- feature_242 <= 104.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_242 >  104.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |--- feature_267 >  121.50\n",
      "|   |   |   |   |   |   |--- feature_353 <= 1.00\n",
      "|   |   |   |   |   |   |   |--- feature_411 <= 114.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_411 >  114.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |--- feature_353 >  1.00\n",
      "|   |   |   |   |   |   |   |--- feature_432 <= 12.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |   |--- feature_432 >  12.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |--- feature_98 >  0.50\n",
      "|   |   |   |   |   |--- feature_537 <= 24.50\n",
      "|   |   |   |   |   |   |--- feature_242 <= 44.50\n",
      "|   |   |   |   |   |   |   |--- feature_243 <= 90.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_243 >  90.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |--- feature_242 >  44.50\n",
      "|   |   |   |   |   |   |   |--- feature_262 <= 9.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_262 >  9.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_537 >  24.50\n",
      "|   |   |   |   |   |   |--- feature_265 <= 126.50\n",
      "|   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_265 >  126.50\n",
      "|   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |--- feature_211 >  28.50\n",
      "|   |   |   |   |--- feature_156 <= 0.50\n",
      "|   |   |   |   |   |--- feature_381 <= 2.50\n",
      "|   |   |   |   |   |   |--- feature_217 <= 1.50\n",
      "|   |   |   |   |   |   |   |--- feature_542 <= 77.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |   |--- feature_542 >  77.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_217 >  1.50\n",
      "|   |   |   |   |   |   |   |--- feature_384 <= 33.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_384 >  33.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |--- feature_381 >  2.50\n",
      "|   |   |   |   |   |   |--- feature_317 <= 0.50\n",
      "|   |   |   |   |   |   |   |--- feature_342 <= 1.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |   |--- feature_342 >  1.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |--- feature_317 >  0.50\n",
      "|   |   |   |   |   |   |   |--- feature_219 <= 18.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |   |--- feature_219 >  18.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |--- feature_156 >  0.50\n",
      "|   |   |   |   |   |--- feature_101 <= 1.00\n",
      "|   |   |   |   |   |   |--- feature_656 <= 1.50\n",
      "|   |   |   |   |   |   |   |--- feature_572 <= 1.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |   |--- feature_572 >  1.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |--- feature_656 >  1.50\n",
      "|   |   |   |   |   |   |   |--- feature_326 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_326 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |--- feature_101 >  1.00\n",
      "|   |   |   |   |   |   |--- feature_271 <= 136.50\n",
      "|   |   |   |   |   |   |   |--- feature_514 <= 3.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_514 >  3.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |--- feature_271 >  136.50\n",
      "|   |   |   |   |   |   |   |--- feature_319 <= 24.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_319 >  24.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |--- feature_568 >  0.50\n",
      "|   |   |--- feature_435 <= 0.50\n",
      "|   |   |   |--- feature_489 <= 47.50\n",
      "|   |   |   |   |--- feature_380 <= 1.50\n",
      "|   |   |   |   |   |--- feature_324 <= 177.50\n",
      "|   |   |   |   |   |   |--- feature_73 <= 8.00\n",
      "|   |   |   |   |   |   |   |--- feature_455 <= 1.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_455 >  1.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_73 >  8.00\n",
      "|   |   |   |   |   |   |   |--- feature_440 <= 9.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_440 >  9.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |--- feature_324 >  177.50\n",
      "|   |   |   |   |   |   |--- feature_271 <= 2.50\n",
      "|   |   |   |   |   |   |   |--- feature_240 <= 124.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_240 >  124.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- feature_271 >  2.50\n",
      "|   |   |   |   |   |   |   |--- feature_237 <= 21.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_237 >  21.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_380 >  1.50\n",
      "|   |   |   |   |   |--- feature_484 <= 25.00\n",
      "|   |   |   |   |   |   |--- feature_374 <= 102.00\n",
      "|   |   |   |   |   |   |   |--- feature_514 <= 84.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_514 >  84.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_374 >  102.00\n",
      "|   |   |   |   |   |   |   |--- feature_297 <= 241.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_297 >  241.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_484 >  25.00\n",
      "|   |   |   |   |   |   |--- feature_270 <= 11.00\n",
      "|   |   |   |   |   |   |   |--- feature_323 <= 143.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_323 >  143.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |--- feature_270 >  11.00\n",
      "|   |   |   |   |   |   |   |--- feature_379 <= 230.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_379 >  230.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |--- feature_489 >  47.50\n",
      "|   |   |   |   |--- feature_347 <= 1.50\n",
      "|   |   |   |   |   |--- feature_344 <= 108.50\n",
      "|   |   |   |   |   |   |--- feature_520 <= 2.50\n",
      "|   |   |   |   |   |   |   |--- feature_377 <= 209.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_377 >  209.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |--- feature_520 >  2.50\n",
      "|   |   |   |   |   |   |   |--- feature_685 <= 27.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_685 >  27.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |--- feature_344 >  108.50\n",
      "|   |   |   |   |   |   |--- feature_512 <= 16.00\n",
      "|   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |--- feature_512 >  16.00\n",
      "|   |   |   |   |   |   |   |--- feature_386 <= 251.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_386 >  251.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |--- feature_347 >  1.50\n",
      "|   |   |   |   |   |--- feature_358 <= 81.00\n",
      "|   |   |   |   |   |   |--- feature_513 <= 71.00\n",
      "|   |   |   |   |   |   |   |--- feature_408 <= 4.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_408 >  4.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |--- feature_513 >  71.00\n",
      "|   |   |   |   |   |   |   |--- feature_405 <= 201.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_405 >  201.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |--- feature_358 >  81.00\n",
      "|   |   |   |   |   |   |--- feature_400 <= 75.50\n",
      "|   |   |   |   |   |   |   |--- feature_317 <= 48.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_317 >  48.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |--- feature_400 >  75.50\n",
      "|   |   |   |   |   |   |   |--- feature_292 <= 27.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_292 >  27.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |--- feature_435 >  0.50\n",
      "|   |   |   |--- feature_347 <= 0.50\n",
      "|   |   |   |   |--- feature_344 <= 27.50\n",
      "|   |   |   |   |   |--- feature_155 <= 0.50\n",
      "|   |   |   |   |   |   |--- feature_652 <= 6.00\n",
      "|   |   |   |   |   |   |   |--- feature_457 <= 63.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_457 >  63.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_652 >  6.00\n",
      "|   |   |   |   |   |   |   |--- feature_238 <= 2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_238 >  2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |--- feature_155 >  0.50\n",
      "|   |   |   |   |   |   |--- feature_544 <= 2.50\n",
      "|   |   |   |   |   |   |   |--- feature_513 <= 3.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_513 >  3.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_544 >  2.50\n",
      "|   |   |   |   |   |   |   |--- feature_349 <= 231.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_349 >  231.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |--- feature_344 >  27.50\n",
      "|   |   |   |   |   |--- feature_214 <= 5.00\n",
      "|   |   |   |   |   |   |--- feature_267 <= 7.00\n",
      "|   |   |   |   |   |   |   |--- feature_217 <= 29.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_217 >  29.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |--- feature_267 >  7.00\n",
      "|   |   |   |   |   |   |   |--- feature_487 <= 2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_487 >  2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |--- feature_214 >  5.00\n",
      "|   |   |   |   |   |   |--- feature_402 <= 123.50\n",
      "|   |   |   |   |   |   |   |--- feature_399 <= 32.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_399 >  32.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |--- feature_402 >  123.50\n",
      "|   |   |   |   |   |   |   |--- feature_514 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_514 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |--- feature_347 >  0.50\n",
      "|   |   |   |   |--- feature_655 <= 0.50\n",
      "|   |   |   |   |   |--- feature_271 <= 1.00\n",
      "|   |   |   |   |   |   |--- feature_484 <= 0.50\n",
      "|   |   |   |   |   |   |   |--- feature_515 <= 52.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_515 >  52.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |--- feature_484 >  0.50\n",
      "|   |   |   |   |   |   |   |--- feature_219 <= 2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_219 >  2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |--- feature_271 >  1.00\n",
      "|   |   |   |   |   |   |--- feature_354 <= 10.50\n",
      "|   |   |   |   |   |   |   |--- feature_385 <= 4.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_385 >  4.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_354 >  10.50\n",
      "|   |   |   |   |   |   |   |--- feature_156 <= 6.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |   |--- feature_156 >  6.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |--- feature_655 >  0.50\n",
      "|   |   |   |   |   |--- feature_514 <= 16.50\n",
      "|   |   |   |   |   |   |--- feature_355 <= 4.50\n",
      "|   |   |   |   |   |   |   |--- feature_150 <= 134.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_150 >  134.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- feature_355 >  4.50\n",
      "|   |   |   |   |   |   |   |--- feature_434 <= 41.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_434 >  41.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |--- feature_514 >  16.50\n",
      "|   |   |   |   |   |   |--- feature_428 <= 30.00\n",
      "|   |   |   |   |   |   |   |--- feature_460 <= 1.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_460 >  1.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |--- feature_428 >  30.00\n",
      "|   |   |   |   |   |   |   |--- feature_434 <= 27.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_434 >  27.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|--- feature_350 >  141.50\n",
      "|   |--- feature_489 <= 26.50\n",
      "|   |   |--- feature_290 <= 33.50\n",
      "|   |   |   |--- feature_486 <= 57.50\n",
      "|   |   |   |   |--- feature_296 <= 2.50\n",
      "|   |   |   |   |   |--- feature_490 <= 87.50\n",
      "|   |   |   |   |   |   |--- feature_315 <= 18.50\n",
      "|   |   |   |   |   |   |   |--- feature_177 <= 1.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_177 >  1.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- feature_315 >  18.50\n",
      "|   |   |   |   |   |   |   |--- feature_328 <= 86.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_328 >  86.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |--- feature_490 >  87.50\n",
      "|   |   |   |   |   |   |--- feature_600 <= 1.50\n",
      "|   |   |   |   |   |   |   |--- feature_457 <= 3.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_457 >  3.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |--- feature_600 >  1.50\n",
      "|   |   |   |   |   |   |   |--- feature_354 <= 76.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_354 >  76.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |--- feature_296 >  2.50\n",
      "|   |   |   |   |   |--- feature_180 <= 3.50\n",
      "|   |   |   |   |   |   |--- feature_156 <= 1.50\n",
      "|   |   |   |   |   |   |   |--- feature_538 <= 1.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |   |--- feature_538 >  1.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |--- feature_156 >  1.50\n",
      "|   |   |   |   |   |   |   |--- feature_265 <= 143.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_265 >  143.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |--- feature_180 >  3.50\n",
      "|   |   |   |   |   |   |--- feature_316 <= 112.50\n",
      "|   |   |   |   |   |   |   |--- feature_488 <= 58.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_488 >  58.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |--- feature_316 >  112.50\n",
      "|   |   |   |   |   |   |   |--- feature_497 <= 13.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |   |--- feature_497 >  13.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |--- feature_486 >  57.50\n",
      "|   |   |   |   |--- feature_656 <= 0.50\n",
      "|   |   |   |   |   |--- feature_152 <= 8.00\n",
      "|   |   |   |   |   |   |--- feature_601 <= 74.00\n",
      "|   |   |   |   |   |   |   |--- feature_189 <= 16.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_189 >  16.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_601 >  74.00\n",
      "|   |   |   |   |   |   |   |--- feature_271 <= 2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_271 >  2.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_152 >  8.00\n",
      "|   |   |   |   |   |   |--- feature_465 <= 11.50\n",
      "|   |   |   |   |   |   |   |--- feature_371 <= 35.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_371 >  35.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |--- feature_465 >  11.50\n",
      "|   |   |   |   |   |   |   |--- feature_431 <= 41.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_431 >  41.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |--- feature_656 >  0.50\n",
      "|   |   |   |   |   |--- feature_467 <= 68.50\n",
      "|   |   |   |   |   |   |--- feature_435 <= 21.50\n",
      "|   |   |   |   |   |   |   |--- feature_125 <= 13.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_125 >  13.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_435 >  21.50\n",
      "|   |   |   |   |   |   |   |--- feature_293 <= 26.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_293 >  26.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |--- feature_467 >  68.50\n",
      "|   |   |   |   |   |   |--- feature_179 <= 3.00\n",
      "|   |   |   |   |   |   |   |--- feature_356 <= 20.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_356 >  20.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |--- feature_179 >  3.00\n",
      "|   |   |   |   |   |   |   |--- feature_316 <= 65.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_316 >  65.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |--- feature_290 >  33.50\n",
      "|   |   |   |--- feature_297 <= 3.50\n",
      "|   |   |   |   |--- feature_486 <= 58.00\n",
      "|   |   |   |   |   |--- feature_186 <= 2.50\n",
      "|   |   |   |   |   |   |--- feature_293 <= 214.50\n",
      "|   |   |   |   |   |   |   |--- feature_464 <= 79.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_464 >  79.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |--- feature_293 >  214.50\n",
      "|   |   |   |   |   |   |   |--- feature_491 <= 189.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_491 >  189.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_186 >  2.50\n",
      "|   |   |   |   |   |   |--- feature_301 <= 54.00\n",
      "|   |   |   |   |   |   |   |--- feature_299 <= 81.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_299 >  81.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |--- feature_301 >  54.00\n",
      "|   |   |   |   |   |   |   |--- feature_381 <= 22.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_381 >  22.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |--- feature_486 >  58.00\n",
      "|   |   |   |   |   |--- feature_656 <= 7.50\n",
      "|   |   |   |   |   |   |--- feature_373 <= 13.50\n",
      "|   |   |   |   |   |   |   |--- feature_374 <= 207.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_374 >  207.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |--- feature_373 >  13.50\n",
      "|   |   |   |   |   |   |   |--- feature_514 <= 39.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_514 >  39.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |--- feature_656 >  7.50\n",
      "|   |   |   |   |   |   |--- feature_440 <= 34.00\n",
      "|   |   |   |   |   |   |   |--- feature_153 <= 5.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_153 >  5.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |--- feature_440 >  34.00\n",
      "|   |   |   |   |   |   |   |--- feature_300 <= 16.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_300 >  16.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_297 >  3.50\n",
      "|   |   |   |   |--- feature_598 <= 0.50\n",
      "|   |   |   |   |   |--- feature_210 <= 4.50\n",
      "|   |   |   |   |   |   |--- feature_405 <= 7.50\n",
      "|   |   |   |   |   |   |   |--- feature_320 <= 212.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_320 >  212.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |--- feature_405 >  7.50\n",
      "|   |   |   |   |   |   |   |--- feature_408 <= 174.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_408 >  174.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |--- feature_210 >  4.50\n",
      "|   |   |   |   |   |   |--- feature_653 <= 67.00\n",
      "|   |   |   |   |   |   |   |--- feature_154 <= 43.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |   |--- feature_154 >  43.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |--- feature_653 >  67.00\n",
      "|   |   |   |   |   |   |   |--- feature_319 <= 64.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_319 >  64.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |--- feature_598 >  0.50\n",
      "|   |   |   |   |   |--- feature_486 <= 9.50\n",
      "|   |   |   |   |   |   |--- feature_427 <= 168.50\n",
      "|   |   |   |   |   |   |   |--- feature_269 <= 1.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_269 >  1.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- feature_427 >  168.50\n",
      "|   |   |   |   |   |   |   |--- feature_381 <= 147.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_381 >  147.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |--- feature_486 >  9.50\n",
      "|   |   |   |   |   |   |--- feature_400 <= 23.50\n",
      "|   |   |   |   |   |   |   |--- feature_573 <= 238.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_573 >  238.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |--- feature_400 >  23.50\n",
      "|   |   |   |   |   |   |   |--- feature_242 <= 10.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_242 >  10.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |--- feature_489 >  26.50\n",
      "|   |   |--- feature_234 <= 0.50\n",
      "|   |   |   |--- feature_402 <= 0.50\n",
      "|   |   |   |   |--- feature_300 <= 20.00\n",
      "|   |   |   |   |   |--- feature_149 <= 2.50\n",
      "|   |   |   |   |   |   |--- feature_494 <= 4.00\n",
      "|   |   |   |   |   |   |   |--- feature_539 <= 64.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_539 >  64.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |--- feature_494 >  4.00\n",
      "|   |   |   |   |   |   |   |--- feature_657 <= 87.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_657 >  87.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |--- feature_149 >  2.50\n",
      "|   |   |   |   |   |   |--- feature_543 <= 74.50\n",
      "|   |   |   |   |   |   |   |--- feature_296 <= 101.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_296 >  101.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- feature_543 >  74.50\n",
      "|   |   |   |   |   |   |   |--- feature_319 <= 68.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_319 >  68.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |--- feature_300 >  20.00\n",
      "|   |   |   |   |   |--- feature_183 <= 1.50\n",
      "|   |   |   |   |   |   |--- feature_188 <= 180.00\n",
      "|   |   |   |   |   |   |   |--- feature_551 <= 10.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_551 >  10.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |--- feature_188 >  180.00\n",
      "|   |   |   |   |   |   |   |--- feature_265 <= 11.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_265 >  11.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |--- feature_183 >  1.50\n",
      "|   |   |   |   |   |   |--- feature_487 <= 49.50\n",
      "|   |   |   |   |   |   |   |--- feature_155 <= 7.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |   |--- feature_155 >  7.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- feature_487 >  49.50\n",
      "|   |   |   |   |   |   |   |--- feature_434 <= 146.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_434 >  146.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |--- feature_402 >  0.50\n",
      "|   |   |   |   |--- feature_103 <= 1.50\n",
      "|   |   |   |   |   |--- feature_276 <= 0.50\n",
      "|   |   |   |   |   |   |--- feature_555 <= 3.50\n",
      "|   |   |   |   |   |   |   |--- feature_466 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |   |--- feature_466 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |--- feature_555 >  3.50\n",
      "|   |   |   |   |   |   |   |--- feature_315 <= 29.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_315 >  29.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |--- feature_276 >  0.50\n",
      "|   |   |   |   |   |   |--- feature_381 <= 58.00\n",
      "|   |   |   |   |   |   |   |--- feature_188 <= 52.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_188 >  52.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |--- feature_381 >  58.00\n",
      "|   |   |   |   |   |   |   |--- feature_211 <= 72.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |   |--- feature_211 >  72.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |--- feature_103 >  1.50\n",
      "|   |   |   |   |   |--- feature_272 <= 6.00\n",
      "|   |   |   |   |   |   |--- feature_349 <= 19.50\n",
      "|   |   |   |   |   |   |   |--- feature_352 <= 148.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |   |--- feature_352 >  148.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 5\n",
      "|   |   |   |   |   |   |--- feature_349 >  19.50\n",
      "|   |   |   |   |   |   |   |--- feature_152 <= 4.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_152 >  4.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |--- feature_272 >  6.00\n",
      "|   |   |   |   |   |   |--- feature_319 <= 126.00\n",
      "|   |   |   |   |   |   |   |--- feature_637 <= 162.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_637 >  162.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |--- feature_319 >  126.00\n",
      "|   |   |   |   |   |   |   |--- feature_468 <= 108.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_468 >  108.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |--- feature_234 >  0.50\n",
      "|   |   |   |--- feature_658 <= 16.00\n",
      "|   |   |   |   |--- feature_345 <= 17.50\n",
      "|   |   |   |   |   |--- feature_526 <= 1.00\n",
      "|   |   |   |   |   |   |--- feature_541 <= 42.00\n",
      "|   |   |   |   |   |   |   |--- feature_603 <= 205.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |   |--- feature_603 >  205.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_541 >  42.00\n",
      "|   |   |   |   |   |   |   |--- feature_320 <= 164.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_320 >  164.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |--- feature_526 >  1.00\n",
      "|   |   |   |   |   |   |--- feature_370 <= 11.50\n",
      "|   |   |   |   |   |   |   |--- feature_284 <= 24.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_284 >  24.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |--- feature_370 >  11.50\n",
      "|   |   |   |   |   |   |   |--- feature_177 <= 136.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |   |--- feature_177 >  136.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |--- feature_345 >  17.50\n",
      "|   |   |   |   |   |--- feature_575 <= 231.50\n",
      "|   |   |   |   |   |   |--- feature_210 <= 21.50\n",
      "|   |   |   |   |   |   |   |--- feature_406 <= 13.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |   |--- feature_406 >  13.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 4\n",
      "|   |   |   |   |   |   |--- feature_210 >  21.50\n",
      "|   |   |   |   |   |   |   |--- feature_555 <= 9.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |   |   |   |--- feature_555 >  9.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |--- feature_575 >  231.50\n",
      "|   |   |   |   |   |   |--- feature_239 <= 110.50\n",
      "|   |   |   |   |   |   |   |--- feature_624 <= 26.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_624 >  26.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |--- feature_239 >  110.50\n",
      "|   |   |   |   |   |   |   |--- feature_398 <= 99.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |   |   |--- feature_398 >  99.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_658 >  16.00\n",
      "|   |   |   |   |--- feature_515 <= 2.50\n",
      "|   |   |   |   |   |--- feature_545 <= 15.00\n",
      "|   |   |   |   |   |   |--- feature_512 <= 45.00\n",
      "|   |   |   |   |   |   |   |--- feature_546 <= 166.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      "|   |   |   |   |   |   |   |--- feature_546 >  166.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_512 >  45.00\n",
      "|   |   |   |   |   |   |   |--- feature_183 <= 11.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |   |--- feature_183 >  11.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |--- feature_545 >  15.00\n",
      "|   |   |   |   |   |   |--- feature_713 <= 29.50\n",
      "|   |   |   |   |   |   |   |--- feature_491 <= 233.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_491 >  233.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_713 >  29.50\n",
      "|   |   |   |   |   |   |   |--- feature_374 <= 0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |   |--- feature_374 >  0.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 9\n",
      "|   |   |   |   |--- feature_515 >  2.50\n",
      "|   |   |   |   |   |--- feature_319 <= 0.50\n",
      "|   |   |   |   |   |   |--- feature_344 <= 4.50\n",
      "|   |   |   |   |   |   |   |--- feature_608 <= 7.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 7\n",
      "|   |   |   |   |   |   |   |--- feature_608 >  7.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 2\n",
      "|   |   |   |   |   |   |--- feature_344 >  4.50\n",
      "|   |   |   |   |   |   |   |--- feature_122 <= 5.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_122 >  5.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 6\n",
      "|   |   |   |   |   |--- feature_319 >  0.50\n",
      "|   |   |   |   |   |   |--- feature_440 <= 68.50\n",
      "|   |   |   |   |   |   |   |--- feature_267 <= 204.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_267 >  204.50\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |--- feature_440 >  68.50\n",
      "|   |   |   |   |   |   |   |--- feature_546 <= 148.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 8\n",
      "|   |   |   |   |   |   |   |--- feature_546 >  148.00\n",
      "|   |   |   |   |   |   |   |   |--- class: 3\n",
      " [0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import export_text\n",
    "text_representation = export_text(dt_clf)\n",
    "print(text_representation, dt_clf.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Circuit HDL: FSM Generator   (Run this cell twice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "from sklearn.tree import _tree\n",
    "\n",
    "def tree_to_code(tree, feature_names):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    \n",
    "    def recurse(node, depth):\n",
    "        indent = \"  \" * depth\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            print (\"{}{}:if ({} <= {})\".format(indent, node, name, int(round(threshold,3)))) \n",
    "            recurse(tree_.children_left[node], depth + 1)\n",
    "            print (\"{}{}:else \".format(indent, node, name, int(round(threshold,3))))\n",
    "            recurse(tree_.children_right[node], depth + 1)\n",
    "        else:\n",
    "            print (\"{} Label<={};\".format(indent, np.argmax(tree_.value[node][0],axis=0)))\n",
    "\n",
    "    recurse(0, 1)\n",
    "\n",
    "cols = range(784)\n",
    "features = ['pixels[{}]'.format(str(i)) for i in cols]\n",
    "class_names = [str(i) for i in dt_clf.classes_]\n",
    "tree_to_code(dt_clf, features)\n",
    "\n",
    "with open('verilog_newFSM.txt', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "def write_file(data_towrite):\n",
    "    with open('verilog_file.v', 'a', encoding='utf-8') as file:\n",
    "        file.writelines(data_towrite)\n",
    "        file.close()\n",
    "        \n",
    "def write_line_file(data_towrite, line_num):\n",
    "    with open('verilog_file.v', 'r', encoding='utf-8') as file:\n",
    "        file_content = file.readlines()\n",
    "        file.close()\n",
    "    file_content[line_num] = file_content[line_num].replace('\\n','') + ' ' + data_towrite + '\\n'  \n",
    "    with open('verilog_file.v', 'w', encoding='utf-8') as file:\n",
    "        file.writelines(file_content)\n",
    "        file.close()\n",
    "        \n",
    "def search_content_file(word):\n",
    "    with open('verilog_file.v', 'r') as file:\n",
    "        file_content = file.readlines()\n",
    "        for line_num,line in enumerate(file_content):\n",
    "            if word in line:\n",
    "                return(line_num)\n",
    "        return(\"content doesn't exists.\")\n",
    "    \n",
    "def update_stateformat_file():\n",
    "    with open('verilog_file.v', 'r', encoding='utf-8') as file:\n",
    "        file_content = file.readlines()\n",
    "        file.close()\n",
    "    for line_num,line in enumerate(file_content):\n",
    "        if 'if' in line:\n",
    "            file_content[line_num] = '16\\'d' + file_content[line_num].strip() + ' \\n'  \n",
    "    with open('verilog_file.v', 'w', encoding='utf-8') as file:\n",
    "        file.writelines(file_content)\n",
    "        file.close()\n",
    "        \n",
    "def clear_file():\n",
    "    with open('verilog_file.v', 'w', encoding='utf-8') as file:\n",
    "        pass\n",
    "        file.close()\n",
    "\n",
    "import itertools\n",
    "with open('verilog_newFSM.txt', 'r') as f:\n",
    "    tree_verilog = f.read()\n",
    "    f.close()\n",
    "\n",
    "clear_file()\n",
    "line_num = 0\n",
    "else_state = 0\n",
    "else_nextif_state = 0\n",
    "curr_line,next_line = itertools.tee(tree_verilog.split('\\n'))\n",
    "next(next_line, None)\n",
    "for i,j in list(zip(curr_line,next_line)):\n",
    "    if 'Label' in i:\n",
    "        pass\n",
    "        #write_file(f'  begin {i.strip()} state<=0;ml_inference_completed<=1; end \\n')\n",
    "    elif 'else' in i and 'Label' in j:\n",
    "        else_state = i.strip().split(':')[0]\n",
    "        line_num = search_content_file(' '+str(else_state)+':if' )\n",
    "        write_line_file(f'\\n       else begin {j.strip()} state<=0;ml_inference_completed<=1; end ', line_num)\n",
    "        #write_file(f'   {i.strip().split(\":\")[-1]} ')\n",
    "    elif 'else' in i and 'if' in j:\n",
    "        else_state = i.strip().split(':')[0]\n",
    "        else_nextif_state = j.strip().split(':')[0]\n",
    "        line_num = search_content_file(' '+str(else_state)+':if' )\n",
    "        write_line_file(f'else begin state<={else_nextif_state}; end ', line_num)\n",
    "    elif 'if' in i and 'Label' in j:\n",
    "        write_file(f'\\n {i.strip()} begin {j.strip()} state<=0;ml_inference_completed<=1; end ')\n",
    "    elif 'if' in i and 'if' in j:\n",
    "        write_file(f'\\n {i.strip()} begin state<={j.strip().split(\":\")[0]}; end \\n ')  \n",
    "update_stateformat_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying the number of \"if\", \"else\" and \"Label\" in verilog with decision tree architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of \"if\" statements 252.\n",
      "Number of \"else\" statements 252.\n",
      "Number of \"label\" statements 253.\n"
     ]
    }
   ],
   "source": [
    "#verifying that the number of \"if\" statements is one less than the number of nodes.\n",
    "file1 = open('verilog_file.v', 'r')\n",
    "contents = file1.readlines()\n",
    "counter_if =0\n",
    "for line in contents:\n",
    "    if 'if' in line:\n",
    "        counter_if = counter_if+1\n",
    "print('Number of \"if\" statements {}.'.format(counter_if))\n",
    "\n",
    "#verifying that the number of \"else\" statements is one less than the number of leaves.\n",
    "file1 = open('verilog_file.v', 'r')\n",
    "contents = file1.readlines()\n",
    "counter_else =0\n",
    "for line in contents:\n",
    "    if 'else' in line:\n",
    "        counter_else = counter_else+1\n",
    "print('Number of \"else\" statements {}.'.format(counter_else))\n",
    "\n",
    "#verifying that the number of \"Label\" statements is equal to the number of leaves.\n",
    "file1 = open('verilog_file.v', 'r')\n",
    "contents = file1.readlines()\n",
    "counter_return =0\n",
    "for line in contents:\n",
    "    if 'Label' in line:\n",
    "        counter_return = counter_return+1\n",
    "print('Number of \"label\" statements {}.'.format(counter_return))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the tree into the source code by rounding the threshold to nearest integer and save it in a py file. This is performed to verify the accuracy by using this dumped decision rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run this cell twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "#https://towardsdatascience.com/scikit-learn-decision-trees-explained-803f3812290d\n",
    "from sklearn.tree import _tree\n",
    "\n",
    "def tree_to_code(tree, feature_names):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    print (\"def decision_tree_inference({}):\".format('feature_set'))\n",
    "    for i,pixel in enumerate(feature_names):\n",
    "            print (\"{}{}\".format(\"  \", pixel+'='+'feature_set['+str(i)+']'))\n",
    "    def recurse(node, depth):\n",
    "        indent = \"  \" * depth\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            print (\"{}if {} <= {}:\".format(indent, name, int(round(threshold,3))))  #convert the threshold to integer\n",
    "            recurse(tree_.children_left[node], depth + 1)\n",
    "            print (\"{}else:  # if {} > {}\".format(indent, name, threshold))\n",
    "            recurse(tree_.children_right[node], depth + 1)\n",
    "        else:\n",
    "            print (\"{}return {}\".format(indent, np.argmax(tree_.value[node][0],axis=0)))\n",
    "\n",
    "    recurse(0, 1)\n",
    "\n",
    "cols = range(784)\n",
    "features = ['pixel'+str(i) for i in cols]\n",
    "class_names = [str(i) for i in dt_clf.classes_]\n",
    "tree_to_code(dt_clf, features)\n",
    "\n",
    "with open('mnist_decision_tree_inference.py', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8167 0.82926\n"
     ]
    }
   ],
   "source": [
    "from mnist_decision_tree_inference import decision_tree_inference\n",
    "y_test_pred_tree = []\n",
    "for i,test_samples in enumerate(X_test):\n",
    "    y_test_pred_tree.append(decision_tree_inference(test_samples))\n",
    "\n",
    "y_train_pred_tree = []\n",
    "for i,test_samples in enumerate(X_train):\n",
    "    y_train_pred_tree.append(decision_tree_inference(test_samples))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_test_pred_tree), accuracy_score(y_train, y_train_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic Locking: XOR key gates at each node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run this cell twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "#https://towardsdatascience.com/scikit-learn-decision-trees-explained-803f3812290d\n",
    "from sklearn.tree import _tree\n",
    "\n",
    "def tree_to_code(tree, feature_names):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    print (\"def dtLOCKED_AllXOR({},{}):\".format('feature_set','key'))\n",
    "    for i,pixel in enumerate(feature_names):\n",
    "            print (\"{}{}\".format(\"  \", pixel+'='+'feature_set['+str(i)+']'))\n",
    "    def recurse(node, depth):\n",
    "        indent = \"  \" * depth\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            #XOR Operation\n",
    "            print (\"{}if {} <= {} and ({} <= {}) ^ key==({} <= {})  :\".format(indent, name, int(round(threshold,3)),name, int(round(threshold,3)),name, int(round(threshold,3))))  #convert the threshold to integer\n",
    "            recurse(tree_.children_left[node], depth + 1)\n",
    "            print (\"{}else:  # if {} > {}\".format(indent, name, threshold))\n",
    "            recurse(tree_.children_right[node], depth + 1)\n",
    "        else:\n",
    "            print (\"{}return {}\".format(indent, np.argmax(tree_.value[node][0],axis=0)))\n",
    "\n",
    "    recurse(0, 1)\n",
    "\n",
    "cols = range(784)\n",
    "features = ['pixel'+str(i) for i in cols]\n",
    "class_names = [str(i) for i in dt_clf.classes_]\n",
    "tree_to_code(dt_clf, features)\n",
    "\n",
    "with open('mnist_DTLock_AllXOR.py', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Verify the accuracy by using this dumped decision rules with correct/incorrect key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct key: 0.8167 0.82926\n",
      "Incorrect key: 0.101 0.1026\n"
     ]
    }
   ],
   "source": [
    "from mnist_DTLock_AllXOR import dtLOCKED_AllXOR\n",
    "y_test_pred_tree = []\n",
    "for i,test_samples in enumerate(X_test):\n",
    "    y_test_pred_tree.append(dtLOCKED_AllXOR(test_samples,0))\n",
    "\n",
    "y_train_pred_tree = []\n",
    "for i,test_samples in enumerate(X_train):\n",
    "    y_train_pred_tree.append(dtLOCKED_AllXOR(test_samples,0))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Correct key:',accuracy_score(y_test, y_test_pred_tree), accuracy_score(y_train, y_train_pred_tree))\n",
    "\n",
    "y_test_pred_tree = []\n",
    "for i,test_samples in enumerate(X_test):\n",
    "    y_test_pred_tree.append(dtLOCKED_AllXOR(test_samples,1))\n",
    "\n",
    "y_train_pred_tree = []\n",
    "for i,test_samples in enumerate(X_train):\n",
    "    y_train_pred_tree.append(dtLOCKED_AllXOR(test_samples,1))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Incorrect key:',accuracy_score(y_test, y_test_pred_tree), accuracy_score(y_train, y_train_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sequential Circuit HDL: FSM Generator   (Run this cell twice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "from sklearn.tree import _tree\n",
    "\n",
    "def tree_to_code(tree, feature_names):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    \n",
    "    def recurse(node, depth):\n",
    "        indent = \"  \" * depth\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            print (\"{}{}:if (({} <= {}) && (({} <= {}) ^ key)==({} <= {})) \".format(indent, node, name, int(round(threshold,3)), name, int(round(threshold,3)), name, int(round(threshold,3)))) \n",
    "            recurse(tree_.children_left[node], depth + 1)\n",
    "            print (\"{}{}:else \".format(indent, node, name, int(round(threshold,3))))\n",
    "            recurse(tree_.children_right[node], depth + 1)\n",
    "        else:\n",
    "            print (\"{} Label<={};\".format(indent, np.argmax(tree_.value[node][0],axis=0)))\n",
    "\n",
    "    recurse(0, 1)\n",
    "\n",
    "cols = range(784)\n",
    "features = ['pixels[{}]'.format(str(i)) for i in cols]\n",
    "class_names = [str(i) for i in dt_clf.classes_]\n",
    "tree_to_code(dt_clf, features)\n",
    "\n",
    "with open('verilog_newFSM.txt', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "def write_file(data_towrite):\n",
    "    with open('verilog_file_allnode_XOR.v', 'a', encoding='utf-8') as file:\n",
    "        file.writelines(data_towrite)\n",
    "        file.close()\n",
    "        \n",
    "def write_line_file(data_towrite, line_num):\n",
    "    with open('verilog_file_allnode_XOR.v', 'r', encoding='utf-8') as file:\n",
    "        file_content = file.readlines()\n",
    "        file.close()\n",
    "    file_content[line_num] = file_content[line_num].replace('\\n','') + ' ' + data_towrite + '\\n'  \n",
    "    with open('verilog_file_allnode_XOR.v', 'w', encoding='utf-8') as file:\n",
    "        file.writelines(file_content)\n",
    "        file.close()\n",
    "        \n",
    "def search_content_file(word):\n",
    "    with open('verilog_file_allnode_XOR.v', 'r') as file:\n",
    "        file_content = file.readlines()\n",
    "        for line_num,line in enumerate(file_content):\n",
    "            if word in line:\n",
    "                return(line_num)\n",
    "        return(\"content doesn't exists.\")\n",
    "    \n",
    "def update_stateformat_file():\n",
    "    with open('verilog_file_allnode_XOR.v', 'r', encoding='utf-8') as file:\n",
    "        file_content = file.readlines()\n",
    "        file.close()\n",
    "    for line_num,line in enumerate(file_content):\n",
    "        if 'if' in line:\n",
    "            file_content[line_num] = '16\\'d' + file_content[line_num].strip() + ' \\n'  \n",
    "    with open('verilog_file_allnode_XOR.v', 'w', encoding='utf-8') as file:\n",
    "        file.writelines(file_content)\n",
    "        file.close()\n",
    "        \n",
    "def clear_file():\n",
    "    with open('verilog_file_allnode_XOR.v', 'w', encoding='utf-8') as file:\n",
    "        pass\n",
    "        file.close()\n",
    "\n",
    "import itertools\n",
    "with open('verilog_newFSM.txt', 'r') as f:\n",
    "    tree_verilog = f.read()\n",
    "    f.close()\n",
    "\n",
    "clear_file()\n",
    "line_num = 0\n",
    "else_state = 0\n",
    "else_nextif_state = 0\n",
    "curr_line,next_line = itertools.tee(tree_verilog.split('\\n'))\n",
    "next(next_line, None)\n",
    "for i,j in list(zip(curr_line,next_line)):\n",
    "    if 'Label' in i:\n",
    "        pass\n",
    "        #write_file(f'  begin {i.strip()} state<=0;ml_inference_completed<=1; end \\n')\n",
    "    elif 'else' in i and 'Label' in j:\n",
    "        else_state = i.strip().split(':')[0]\n",
    "        line_num = search_content_file(' '+str(else_state)+':if' )\n",
    "        write_line_file(f'\\n       else begin {j.strip()} state<=0;ml_inference_completed<=1; end ', line_num)\n",
    "        #write_file(f'   {i.strip().split(\":\")[-1]} ')\n",
    "    elif 'else' in i and 'if' in j:\n",
    "        else_state = i.strip().split(':')[0]\n",
    "        else_nextif_state = j.strip().split(':')[0]\n",
    "        line_num = search_content_file(' '+str(else_state)+':if' )\n",
    "        write_line_file(f'else begin state<={else_nextif_state}; end ', line_num)\n",
    "    elif 'if' in i and 'Label' in j:\n",
    "        write_file(f'\\n {i.strip()} begin {j.strip()} state<=0;ml_inference_completed<=1; end ')\n",
    "    elif 'if' in i and 'if' in j:\n",
    "        write_file(f'\\n {i.strip()} begin state<={j.strip().split(\":\")[0]}; end \\n ')  \n",
    "update_stateformat_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic Locking: XNOR key gates at each node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run this cell twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "#https://towardsdatascience.com/scikit-learn-decision-trees-explained-803f3812290d\n",
    "from sklearn.tree import _tree\n",
    "\n",
    "def tree_to_code(tree, feature_names):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    print (\"def dtLOCKED_AllXNOR({},{}):\".format('feature_set','key'))\n",
    "    for i,pixel in enumerate(feature_names):\n",
    "            print (\"{}{}\".format(\"  \", pixel+'='+'feature_set['+str(i)+']'))\n",
    "    def recurse(node, depth):\n",
    "        indent = \"  \" * depth\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            #XNOR Operation\n",
    "            print (\"{}if {} <= {} and not(({} <= {}) ^ key)==({} <= {})  :\".format(indent, name, int(round(threshold,3)),name, int(round(threshold,3)),name, int(round(threshold,3))))  #convert the threshold to integer\n",
    "            recurse(tree_.children_left[node], depth + 1)\n",
    "            print (\"{}else:  # if {} > {}\".format(indent, name, threshold))\n",
    "            recurse(tree_.children_right[node], depth + 1)\n",
    "        else:\n",
    "            print (\"{}return {}\".format(indent, np.argmax(tree_.value[node][0],axis=0)))\n",
    "\n",
    "    recurse(0, 1)\n",
    "\n",
    "cols = range(784)\n",
    "features = ['pixel'+str(i) for i in cols]\n",
    "class_names = [str(i) for i in dt_clf.classes_]\n",
    "tree_to_code(dt_clf, features)\n",
    "\n",
    "with open('mnist_DTLock_AllXNOR.py', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Verify the accuracy by using this dumped decision rules with correct/incorrect key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct key: 0.8167 0.82926\n",
      "Incorrect key: 0.101 0.1026\n"
     ]
    }
   ],
   "source": [
    "from mnist_DTLock_AllXNOR import dtLOCKED_AllXNOR\n",
    "y_test_pred_tree = []\n",
    "for i,test_samples in enumerate(X_test):\n",
    "    y_test_pred_tree.append(dtLOCKED_AllXNOR(test_samples,1))\n",
    "\n",
    "y_train_pred_tree = []\n",
    "for i,test_samples in enumerate(X_train):\n",
    "    y_train_pred_tree.append(dtLOCKED_AllXNOR(test_samples,1))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Correct key:',accuracy_score(y_test, y_test_pred_tree), accuracy_score(y_train, y_train_pred_tree))\n",
    "\n",
    "y_test_pred_tree = []\n",
    "for i,test_samples in enumerate(X_test):\n",
    "    y_test_pred_tree.append(dtLOCKED_AllXNOR(test_samples,0))\n",
    "\n",
    "y_train_pred_tree = []\n",
    "for i,test_samples in enumerate(X_train):\n",
    "    y_train_pred_tree.append(dtLOCKED_AllXNOR(test_samples,0))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Incorrect key:',accuracy_score(y_test, y_test_pred_tree), accuracy_score(y_train, y_train_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sequential Circuit HDL: FSM Generator   (Run this cell twice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "from sklearn.tree import _tree\n",
    "\n",
    "def tree_to_code(tree, feature_names):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    \n",
    "    def recurse(node, depth):\n",
    "        indent = \"  \" * depth\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            print (\"{}{}:if (({} <= {}) && (({} <= {}) ~^ key)==({} <= {})) \".format(indent, node, name, int(round(threshold,3)), name, int(round(threshold,3)), name, int(round(threshold,3)))) \n",
    "            recurse(tree_.children_left[node], depth + 1)\n",
    "            print (\"{}{}:else \".format(indent, node, name, int(round(threshold,3))))\n",
    "            recurse(tree_.children_right[node], depth + 1)\n",
    "        else:\n",
    "            print (\"{} Label<={};\".format(indent, np.argmax(tree_.value[node][0],axis=0)))\n",
    "\n",
    "    recurse(0, 1)\n",
    "\n",
    "cols = range(784)\n",
    "features = ['pixels[{}]'.format(str(i)) for i in cols]\n",
    "class_names = [str(i) for i in dt_clf.classes_]\n",
    "tree_to_code(dt_clf, features)\n",
    "\n",
    "with open('verilog_newFSM.txt', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "def write_file(data_towrite):\n",
    "    with open('verilog_file_allnode_XNOR.v', 'a', encoding='utf-8') as file:\n",
    "        file.writelines(data_towrite)\n",
    "        file.close()\n",
    "        \n",
    "def write_line_file(data_towrite, line_num):\n",
    "    with open('verilog_file_allnode_XNOR.v', 'r', encoding='utf-8') as file:\n",
    "        file_content = file.readlines()\n",
    "        file.close()\n",
    "    file_content[line_num] = file_content[line_num].replace('\\n','') + ' ' + data_towrite + '\\n'  \n",
    "    with open('verilog_file_allnode_XNOR.v', 'w', encoding='utf-8') as file:\n",
    "        file.writelines(file_content)\n",
    "        file.close()\n",
    "        \n",
    "def search_content_file(word):\n",
    "    with open('verilog_file_allnode_XNOR.v', 'r') as file:\n",
    "        file_content = file.readlines()\n",
    "        for line_num,line in enumerate(file_content):\n",
    "            if word in line:\n",
    "                return(line_num)\n",
    "        return(\"content doesn't exists.\")\n",
    "    \n",
    "def update_stateformat_file():\n",
    "    with open('verilog_file_allnode_XNOR.v', 'r', encoding='utf-8') as file:\n",
    "        file_content = file.readlines()\n",
    "        file.close()\n",
    "    for line_num,line in enumerate(file_content):\n",
    "        if 'if' in line:\n",
    "            file_content[line_num] = '16\\'d' + file_content[line_num].strip() + ' \\n'  \n",
    "    with open('verilog_file_allnode_XNOR.v', 'w', encoding='utf-8') as file:\n",
    "        file.writelines(file_content)\n",
    "        file.close()\n",
    "        \n",
    "def clear_file():\n",
    "    with open('verilog_file_allnode_XNOR.v', 'w', encoding='utf-8') as file:\n",
    "        pass\n",
    "        file.close()\n",
    "\n",
    "import itertools\n",
    "with open('verilog_newFSM.txt', 'r') as f:\n",
    "    tree_verilog = f.read()\n",
    "    f.close()\n",
    "\n",
    "clear_file()\n",
    "line_num = 0\n",
    "else_state = 0\n",
    "else_nextif_state = 0\n",
    "curr_line,next_line = itertools.tee(tree_verilog.split('\\n'))\n",
    "next(next_line, None)\n",
    "for i,j in list(zip(curr_line,next_line)):\n",
    "    if 'Label' in i:\n",
    "        pass\n",
    "        #write_file(f'  begin {i.strip()} state<=0;ml_inference_completed<=1; end \\n')\n",
    "    elif 'else' in i and 'Label' in j:\n",
    "        else_state = i.strip().split(':')[0]\n",
    "        line_num = search_content_file(' '+str(else_state)+':if' )\n",
    "        write_line_file(f'\\n       else begin {j.strip()} state<=0;ml_inference_completed<=1; end ', line_num)\n",
    "        #write_file(f'   {i.strip().split(\":\")[-1]} ')\n",
    "    elif 'else' in i and 'if' in j:\n",
    "        else_state = i.strip().split(':')[0]\n",
    "        else_nextif_state = j.strip().split(':')[0]\n",
    "        line_num = search_content_file(' '+str(else_state)+':if' )\n",
    "        write_line_file(f'else begin state<={else_nextif_state}; end ', line_num)\n",
    "    elif 'if' in i and 'Label' in j:\n",
    "        write_file(f'\\n {i.strip()} begin {j.strip()} state<=0;ml_inference_completed<=1; end ')\n",
    "    elif 'if' in i and 'if' in j:\n",
    "        write_file(f'\\n {i.strip()} begin state<={j.strip().split(\":\")[0]}; end \\n ')  \n",
    "update_stateformat_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic Locking: Mix of XOR/XNOR key gates selected randomly at each node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Key generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 1 1 0 1 1 1 0 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 1 0 1 1 0 1 0\n",
      " 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1 0 0 0 0 1 1 1 1 0 1 0 0 1 0 0 0 0 1 1 0 0 1\n",
      " 0 0 0 1 0 0 1 1 0 0 1 0 0 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 1 0 0 0 0 1 0 1 0\n",
      " 0 1 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 1 0 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 0 1 0 1 0 1 1 0 0 0 1 0 1 1 0 1 0 1 0 1 0 1 1 1 1 0 0 1 1 1 0 0 1 0 1 0 1\n",
      " 1 0 1 0 1 0 1 1 1 0 0 1 0 1 0 0 0 0 1 0 1 0 1 0 1 1 0 1 1 1 1 0 1 0 0 1 1\n",
      " 1 1 1 1 0 1 1 0 1 0 1 0 1 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "key = np.random.randint(0,2,counter_if)\n",
    "print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Selecting gates between XOR and XNOR based on key value. 0-XOR, 1-XNOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run this cell twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "#https://towardsdatascience.com/scikit-learn-decision-trees-explained-803f3812290d\n",
    "from sklearn.tree import _tree\n",
    "def tree_to_code(tree, feature_names, key, key_counter):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    print (\"def dtLOCKED_XOR_XNOR({},{}):\".format('feature_set','key'))\n",
    "    for i,pixel in enumerate(feature_names):\n",
    "            print (\"{}{}\".format(\"  \", pixel+'='+'feature_set['+str(i)+']'))\n",
    "    def recurse(node, depth, key_counter):\n",
    "        indent = \"  \" * depth\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            if key[key_counter] == 0:\n",
    "                print (\"{}if ({} <= {}) and (({} <= {}) ^ key[ ])==({} <= {})  :\".format(indent, name, int(round(threshold,3)),name, int(round(threshold,3)), name, int(round(threshold,3))))  #convert the threshold to integer\n",
    "            else:\n",
    "                print (\"{}if {} <= {} and not(({} <= {}) ^ key[ ])==({} <= {})  :\".format(indent, name, int(round(threshold,3)),name, int(round(threshold,3)), name, int(round(threshold,3))))  #convert the threshold to integer\n",
    "            key_counter = key_counter +1\n",
    "            recurse(tree_.children_left[node], depth + 1, key_counter)\n",
    "            print (\"{}else:  # if {} > {}\".format(indent, name, threshold))\n",
    "            recurse(tree_.children_right[node], depth + 1, key_counter)\n",
    "        else:\n",
    "            print (\"{}return {}\".format(indent, np.argmax(tree_.value[node][0],axis=0)))\n",
    "\n",
    "    recurse(0, 1, key_counter)\n",
    "\n",
    "cols = range(784)\n",
    "features = ['pixel'+str(i) for i in cols]\n",
    "class_names = [str(i) for i in dt_clf.classes_]\n",
    "key_counter=0\n",
    "tree_to_code(dt_clf, features, key, key_counter)\n",
    "\n",
    "with open('mnist_DTLock_XOR_XNOR.py', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Adding appropirate XOR/XNOR for key value inside key[_] field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_key_lines(file_name):\n",
    "    with open(file_name, 'r') as file:\n",
    "        key_line_num = []\n",
    "        file_content = file.readlines()\n",
    "        for line_num,line in enumerate(file_content):\n",
    "            if 'key[ ]' in line:\n",
    "                key_line_num.append(line_num)        \n",
    "        return(key_line_num)\n",
    "\n",
    "def write_line_file(file_name, data_towrite, line_num):\n",
    "    with open(file_name, 'r', encoding='utf-8') as file:\n",
    "        file_content = file.readlines()\n",
    "        file.close()\n",
    "    file_content[line_num] = file_content[line_num].replace('key[ ]',f'key[{data_towrite}]')   \n",
    "    with open(file_name, 'w', encoding='utf-8') as file:\n",
    "        file.writelines(file_content)\n",
    "        file.close()\n",
    "    \n",
    "def correct_keygate_xor_xnor(file_name, key):\n",
    "    with open(file_name, 'r', encoding='utf-8') as file:\n",
    "        file_content = file.readlines()\n",
    "        file.close()\n",
    "    for line_num,line in enumerate(file_content):\n",
    "            if 'key[' in line:\n",
    "                key_index = int(line.split('key[')[1].split(']')[0])\n",
    "                if (key[key_index] == 1 and 'not' in line):\n",
    "                    pass\n",
    "                \n",
    "                if (key[key_index] == 1 and 'not' not in line):\n",
    "                    file_content[line_num] = ''.join(file_content[line_num].split('and')[0]+ 'and not' + file_content[line_num].split('and')[-1])\n",
    "                \n",
    "                if (key[key_index] == 0 and 'not' not in line):\n",
    "                    pass\n",
    "                \n",
    "                if (key[key_index] == 0 and 'not' in line):\n",
    "                    file_content[line_num] = file_content[line_num].replace('not','')\n",
    "                    \n",
    "    with open(file_name, 'w', encoding='utf-8') as file:\n",
    "        file.writelines(file_content)\n",
    "        file.close()\n",
    "                    \n",
    "def inspect_keygate_xor_xnor(file_name, key):\n",
    "    with open(file_name, 'r', encoding='utf-8') as file:\n",
    "        file_content = file.readlines()\n",
    "        file.close()\n",
    "    for line_num,line in enumerate(file_content):\n",
    "            if 'key[' in line:\n",
    "                key_index = int(line.split('key[')[1].split(']')[0])\n",
    "                if (key[key_index] == 1 and 'not' in line) or (key[key_index] == 0 and 'not' not in line):\n",
    "                    pass\n",
    "                else:\n",
    "                    pdb.set_trace()\n",
    "                    \n",
    "key_line_num = search_key_lines('mnist_DTLock_XOR_XNOR.py')\n",
    "for i,line_num in enumerate(key_line_num):\n",
    "    write_line_file('mnist_DTLock_XOR_XNOR.py', i, line_num)\n",
    "correct_keygate_xor_xnor('mnist_DTLock_XOR_XNOR.py', key)\n",
    "\n",
    "#Performing final inspection\n",
    "inspect_keygate_xor_xnor('mnist_DTLock_XOR_XNOR.py', key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Verify the accuracy by using this dumped decision rules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct key: 0.8167 0.82926\n"
     ]
    }
   ],
   "source": [
    "from mnist_DTLock_XOR_XNOR import dtLOCKED_XOR_XNOR\n",
    "y_test_pred_tree = []\n",
    "for i,test_samples in enumerate(X_test):\n",
    "    y_test_pred_tree.append(dtLOCKED_XOR_XNOR(test_samples,key))\n",
    "\n",
    "y_train_pred_tree = []\n",
    "for i,test_samples in enumerate(X_train):\n",
    "    y_train_pred_tree.append(dtLOCKED_XOR_XNOR(test_samples,key))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Correct key:',accuracy_score(y_test, y_test_pred_tree), accuracy_score(y_train, y_train_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Verify the accuracy by using this dumped decision rules with incorrect key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect key: 0.1679 0.15952\n"
     ]
    }
   ],
   "source": [
    "incorrect_key=key.copy()\n",
    "y_test_pred_tree = []\n",
    "#shuffle the key list to simulate incorrect key\n",
    "np.random.shuffle(incorrect_key)\n",
    "for i,test_samples in enumerate(X_test):\n",
    "    y_test_pred_tree.append(dtLOCKED_XOR_XNOR(test_samples,incorrect_key))\n",
    "\n",
    "y_train_pred_tree = []\n",
    "for i,test_samples in enumerate(X_train):\n",
    "    y_train_pred_tree.append(dtLOCKED_XOR_XNOR(test_samples,incorrect_key))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Incorrect key:',accuracy_score(y_test, y_test_pred_tree), accuracy_score(y_train, y_train_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sequential Circuit HDL: FSM Generator   (Run this cell twice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "from sklearn.tree import _tree\n",
    "\n",
    "def tree_to_code(tree, feature_names):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    \n",
    "    def recurse(node, depth):\n",
    "        indent = \"  \" * depth\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            print (\"{}{}:if (({} <= {}) && (({} <= {}) ^ key)==({} <= {})) \".format(indent, node, name, int(round(threshold,3)), name, int(round(threshold,3)), name, int(round(threshold,3)))) \n",
    "            recurse(tree_.children_left[node], depth + 1)\n",
    "            print (\"{}{}:else \".format(indent, node, name, int(round(threshold,3))))\n",
    "            recurse(tree_.children_right[node], depth + 1)\n",
    "        else:\n",
    "            print (\"{} Label<={};\".format(indent, np.argmax(tree_.value[node][0],axis=0)))\n",
    "\n",
    "    recurse(0, 1)\n",
    "\n",
    "cols = range(784)\n",
    "features = ['pixels[{}]'.format(str(i)) for i in cols]\n",
    "class_names = [str(i) for i in dt_clf.classes_]\n",
    "tree_to_code(dt_clf, features)\n",
    "\n",
    "with open('verilog_newFSM.txt', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "def write_file(data_towrite):\n",
    "    with open('verilog_file_allnode_XOR_XNOR.v', 'a', encoding='utf-8') as file:\n",
    "        file.writelines(data_towrite)\n",
    "        file.close()\n",
    "        \n",
    "def write_line_file(data_towrite, line_num):\n",
    "    with open('verilog_file_allnode_XOR_XNOR.v', 'r', encoding='utf-8') as file:\n",
    "        file_content = file.readlines()\n",
    "        file.close()\n",
    "    file_content[line_num] = file_content[line_num].replace('\\n','') + ' ' + data_towrite + '\\n'  \n",
    "    with open('verilog_file_allnode_XOR_XNOR.v', 'w', encoding='utf-8') as file:\n",
    "        file.writelines(file_content)\n",
    "        file.close()\n",
    "        \n",
    "def search_content_file(word):\n",
    "    with open('verilog_file_allnode_XOR_XNOR.v', 'r') as file:\n",
    "        file_content = file.readlines()\n",
    "        for line_num,line in enumerate(file_content):\n",
    "            if word in line:\n",
    "                return(line_num)\n",
    "        return(\"content doesn't exists.\")\n",
    "    \n",
    "def update_stateformat_file():\n",
    "    with open('verilog_file_allnode_XOR_XNOR.v', 'r', encoding='utf-8') as file:\n",
    "        file_content = file.readlines()\n",
    "        file.close()\n",
    "    for line_num,line in enumerate(file_content):\n",
    "        if 'if' in line:\n",
    "            file_content[line_num] = '16\\'d' + file_content[line_num].strip() + ' \\n'  \n",
    "    with open('verilog_file_allnode_XOR_XNOR.v', 'w', encoding='utf-8') as file:\n",
    "        file.writelines(file_content)\n",
    "        file.close()\n",
    "        \n",
    "def clear_file():\n",
    "    with open('verilog_file_allnode_XOR_XNOR.v', 'w', encoding='utf-8') as file:\n",
    "        pass\n",
    "        file.close()\n",
    "\n",
    "import itertools\n",
    "with open('verilog_newFSM.txt', 'r') as f:\n",
    "    tree_verilog = f.read()\n",
    "    f.close()\n",
    "\n",
    "clear_file()\n",
    "line_num = 0\n",
    "else_state = 0\n",
    "else_nextif_state = 0\n",
    "curr_line,next_line = itertools.tee(tree_verilog.split('\\n'))\n",
    "next(next_line, None)\n",
    "for i,j in list(zip(curr_line,next_line)):\n",
    "    if 'Label' in i:\n",
    "        pass\n",
    "        #write_file(f'  begin {i.strip()} state<=0;ml_inference_completed<=1; end \\n')\n",
    "    elif 'else' in i and 'Label' in j:\n",
    "        else_state = i.strip().split(':')[0]\n",
    "        line_num = search_content_file(' '+str(else_state)+':if' )\n",
    "        write_line_file(f'\\n       else begin {j.strip()} state<=0;ml_inference_completed<=1; end ', line_num)\n",
    "        #write_file(f'   {i.strip().split(\":\")[-1]} ')\n",
    "    elif 'else' in i and 'if' in j:\n",
    "        else_state = i.strip().split(':')[0]\n",
    "        else_nextif_state = j.strip().split(':')[0]\n",
    "        line_num = search_content_file(' '+str(else_state)+':if' )\n",
    "        write_line_file(f'else begin state<={else_nextif_state}; end ', line_num)\n",
    "    elif 'if' in i and 'Label' in j:\n",
    "        write_file(f'\\n {i.strip()} begin {j.strip()} state<=0;ml_inference_completed<=1; end ')\n",
    "    elif 'if' in i and 'if' in j:\n",
    "        write_file(f'\\n {i.strip()} begin state<={j.strip().split(\":\")[0]}; end \\n ')  \n",
    "update_stateformat_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('verilog_file_allnode_XOR_XNOR.v', 'r', encoding='utf-8') as file:\n",
    "    file_content = file.readlines()\n",
    "    file.close()\n",
    "\n",
    "key_index = 0\n",
    "for line_num,line in enumerate(file_content):\n",
    "    if 'key' in line:\n",
    "        file_content[line_num] = file_content[line_num].replace('key',f'key[{key_index}]')\n",
    "        if key[key_index]==1: file_content[line_num] = file_content[line_num].replace('^','~^')\n",
    "        key_index = key_index+1\n",
    "with open('verilog_file_allnode_XOR_XNOR.v', 'w', encoding='utf-8') as file:\n",
    "        file.writelines(file_content)\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This should go to the verilog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg [251:0] key;\n",
      "initial key ={1'b1, 1'b1, 1'b1, 1'b1, 1'b1, 1'b1, 1'b1, 1'b1, 1'b1, 1'b1, 1'b0, 1'b0, 1'b0, 1'b0, 1'b0, 1'b0, 1'b0, 1'b1, 1'b0, 1'b1, 1'b0, 1'b1, 1'b0, 1'b1, 1'b1, 1'b0, 1'b1, 1'b1, 1'b1, 1'b1, 1'b1, 1'b1, 1'b0, 1'b0, 1'b1, 1'b0, 1'b1, 1'b1, 1'b1, 1'b1, 1'b0, 1'b1, 1'b1, 1'b0, 1'b1, 1'b0, 1'b1, 1'b0, 1'b1, 1'b0, 1'b0, 1'b0, 1'b0, 1'b1, 1'b0, 1'b1, 1'b0, 1'b0, 1'b1, 1'b1, 1'b1, 1'b0, 1'b1, 1'b0, 1'b1, 1'b0, 1'b1, 1'b1, 1'b0, 1'b1, 1'b0, 1'b1, 1'b0, 1'b0, 1'b1, 1'b1, 1'b1, 1'b0, 1'b0, 1'b1, 1'b1, 1'b1, 1'b1, 1'b0, 1'b1, 1'b0, 1'b1, 1'b0, 1'b1, 1'b0, 1'b1, 1'b1, 1'b0, 1'b1, 1'b0, 1'b0, 1'b0, 1'b1, 1'b1, 1'b0, 1'b1, 1'b0, 1'b1, 1'b0, 1'b1, 1'b1, 1'b0, 1'b1, 1'b1, 1'b0, 1'b1, 1'b1, 1'b1, 1'b1, 1'b0, 1'b0, 1'b1, 1'b0, 1'b1, 1'b0, 1'b0, 1'b0, 1'b0, 1'b0, 1'b0, 1'b0, 1'b1, 1'b0, 1'b1, 1'b1, 1'b1, 1'b1, 1'b0, 1'b1, 1'b0, 1'b0, 1'b1, 1'b0, 1'b0, 1'b1, 1'b0, 1'b0, 1'b1, 1'b0, 1'b1, 1'b0, 1'b0, 1'b0, 1'b0, 1'b1, 1'b1, 1'b1, 1'b0, 1'b0, 1'b1, 1'b0, 1'b0, 1'b0, 1'b1, 1'b1, 1'b1, 1'b0, 1'b1, 1'b1, 1'b0, 1'b0, 1'b0, 1'b1, 1'b0, 1'b0, 1'b1, 1'b1, 1'b0, 1'b0, 1'b1, 1'b0, 1'b0, 1'b0, 1'b1, 1'b0, 1'b0, 1'b1, 1'b1, 1'b0, 1'b0, 1'b0, 1'b0, 1'b1, 1'b0, 1'b0, 1'b1, 1'b0, 1'b1, 1'b1, 1'b1, 1'b1, 1'b0, 1'b0, 1'b0, 1'b0, 1'b1, 1'b1, 1'b1, 1'b0, 1'b1, 1'b1, 1'b1, 1'b0, 1'b1, 1'b0, 1'b0, 1'b1, 1'b1, 1'b1, 1'b0, 1'b0, 1'b1, 1'b0, 1'b1, 1'b1, 1'b0, 1'b1, 1'b0, 1'b0, 1'b0, 1'b1, 1'b0, 1'b0, 1'b1, 1'b0, 1'b1, 1'b0, 1'b0, 1'b0, 1'b0, 1'b0, 1'b0, 1'b0, 1'b1, 1'b1, 1'b1, 1'b0, 1'b1, 1'b1, 1'b1, 1'b0, 1'b1, 1'b1, 1'b0, 1'b1, 1'b0, 1'b0};\n"
     ]
    }
   ],
   "source": [
    "reverse_order_key = key.copy()\n",
    "reverse_order_key = list(reverse_order_key)\n",
    "reverse_order_key.reverse()\n",
    "#reversing the order because in verilog the leftmost is MSB (key[counter_if]) and rightmost is LSB key[0].\n",
    "print(f'reg [{counter_if-1}:0] key;')\n",
    "print(f\"initial key =\" + \"{\" + \", \".join([\"1'b\"+str(x) for x in reverse_order_key]) + \"};\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic Locking: Mix of XOR/XNOR key gates selected randomly at only few nodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Key generation : Input the percentage of nodes you want to lock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input the percentage of nodes you want to lock out of 252.\n",
      "0.85\n",
      "[0 1 1 1 2 1 0 0 0 0 1 0 2 2 0 1 1 1 0 1 1 1 0 1 0 1 1 1 2 2 0 1 1 2 1 0 0\n",
      " 1 1 2 2 2 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 1 2 0 0 1 0 0 2 1 0 2 1 1 0 1 1 0\n",
      " 0 1 1 1 1 0 2 0 2 0 1 1 0 0 0 1 1 1 0 0 0 1 0 0 0 0 1 1 1 1 0 2 0 0 2 1 2\n",
      " 1 1 0 0 1 1 0 1 0 1 1 2 1 0 0 2 1 2 0 0 1 1 1 0 0 0 1 0 1 1 1 0 1 0 0 2 1\n",
      " 1 2 1 1 0 0 0 2 0 0 0 0 1 0 0 1 0 0 0 1 0 2 1 1 1 1 2 0 0 0 2 1 0 0 1 0 2\n",
      " 2 0 0 0 1 0 1 1 0 1 1 1 0 0 1 1 2 0 2 0 2 1 2 0 0 0 0 0 2 1 1 1 0 0 1 0 0\n",
      " 0 0 1 0 1 2 0 2 2 0 1 0 1 1 2 1 1 0 0 1 0 0 0 1 2 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(f'Input the percentage of nodes you want to lock out of {counter_if}.')\n",
    "locking_fraction=float(input())\n",
    "locking_fraction = int(locking_fraction*counter_if)\n",
    "key = np.random.randint(0,3,counter_if)\n",
    "key[0:int(locking_fraction/2)] = 0\n",
    "key[int(locking_fraction/2):locking_fraction] = 1\n",
    "key[locking_fraction:] = 2\n",
    "np.random.shuffle(key)\n",
    "print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Selecting gates between XOR and XNOR based on key value. 0-XOR, 1-XNOR, 2-No Lock"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run this cell twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "#https://towardsdatascience.com/scikit-learn-decision-trees-explained-803f3812290d\n",
    "from sklearn.tree import _tree\n",
    "def tree_to_code(tree, feature_names, key, key_counter):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    print (\"def dtLOCKED_Some_XOR_XNOR({},{}):\".format('feature_set','key'))\n",
    "    for i,pixel in enumerate(feature_names):\n",
    "            print (\"{}{}\".format(\"  \", pixel+'='+'feature_set['+str(i)+']'))\n",
    "    def recurse(node, depth, key_counter):\n",
    "        indent = \"  \" * depth\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            if key[key_counter] == 0:\n",
    "                print (\"{}if ({} <= {}) and (({} <= {}) ^ key[ ])==({} <= {})  :\".format(indent, name, int(round(threshold,3)),name, int(round(threshold,3)), name, int(round(threshold,3))))  #convert the threshold to integer\n",
    "            elif key[key_counter] == 1:\n",
    "                print (\"{}if ({} <= {}) and not(({} <= {}) ^ key[ ])==({} <= {})  :\".format(indent, name, int(round(threshold,3)),name, int(round(threshold,3)), name, int(round(threshold,3))))  #convert the threshold to integer\n",
    "            else:\n",
    "                print (\"{}if ({} <= {}):\".format(indent, name, int(round(threshold,3))))  #convert the threshold to integer\n",
    "            key_counter = key_counter +1\n",
    "            recurse(tree_.children_left[node], depth + 1, key_counter)\n",
    "            print (\"{}else:  # if {} > {}\".format(indent, name, threshold))\n",
    "            recurse(tree_.children_right[node], depth + 1, key_counter)\n",
    "        else:\n",
    "            print (\"{}return {}\".format(indent, np.argmax(tree_.value[node][0],axis=0)))\n",
    "\n",
    "    recurse(0, 1, key_counter)\n",
    "\n",
    "cols = range(784)\n",
    "features = ['pixel'+str(i) for i in cols]\n",
    "class_names = [str(i) for i in dt_clf.classes_]\n",
    "key_counter=0\n",
    "tree_to_code(dt_clf, features, key, key_counter)\n",
    "\n",
    "with open('mnist_DTLock_Some_XOR_XNOR.py', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Adding appropirate XOR/XNOR for key value inside key[_] field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "def search_key_lines(file_name):\n",
    "    with open(file_name, 'r') as file:\n",
    "        key_line_num = []\n",
    "        file_content = file.readlines()\n",
    "        for line_num,line in enumerate(file_content):\n",
    "            if 'key[ ]' in line:\n",
    "                key_line_num.append(line_num)        \n",
    "        return(key_line_num)\n",
    "\n",
    "def write_line_file(file_name, data_towrite, line_num):\n",
    "    with open(file_name, 'r', encoding='utf-8') as file:\n",
    "        file_content = file.readlines()\n",
    "        file.close()\n",
    "    file_content[line_num] = file_content[line_num].replace('key[ ]',f'key[{data_towrite}]')   \n",
    "    with open(file_name, 'w', encoding='utf-8') as file:\n",
    "        file.writelines(file_content)\n",
    "        file.close()\n",
    "    \n",
    "def correct_keygate_xor_xnor(file_name, key):\n",
    "    with open(file_name, 'r', encoding='utf-8') as file:\n",
    "        file_content = file.readlines()\n",
    "        file.close()\n",
    "    for line_num,line in enumerate(file_content):\n",
    "            if 'key[' in line:\n",
    "                key_index = int(line.split('key[')[1].split(']')[0])\n",
    "                if (key[key_index] == 1 and 'not' in line):\n",
    "                    pass\n",
    "                \n",
    "                if (key[key_index] == 1 and 'not' not in line):\n",
    "                    file_content[line_num] = ''.join(file_content[line_num].split('and')[0]+ 'and not' + file_content[line_num].split('and')[-1])\n",
    "                \n",
    "                if (key[key_index] == 0 and 'not' not in line):\n",
    "                    pass\n",
    "                \n",
    "                if (key[key_index] == 0 and 'not' in line):\n",
    "                    file_content[line_num] = file_content[line_num].replace('not','')\n",
    "                    \n",
    "                if (key[key_index] == 2 ):\n",
    "                    file_content[line_num] = file_content[line_num].split('and')[0]+': \\n'\n",
    "                    \n",
    "    with open(file_name, 'w', encoding='utf-8') as file:\n",
    "        file.writelines(file_content)\n",
    "        file.close()\n",
    "                    \n",
    "def inspect_keygate_xor_xnor(file_name, key):\n",
    "    with open(file_name, 'r', encoding='utf-8') as file:\n",
    "        file_content = file.readlines()\n",
    "        file.close()\n",
    "    for line_num,line in enumerate(file_content):\n",
    "            if 'key[' in line:\n",
    "                key_index = int(line.split('key[')[1].split(']')[0])\n",
    "                if (key[key_index] == 1 and 'not' in line) or (key[key_index] == 0 and 'not' not in line):\n",
    "                    pass\n",
    "                elif (key[key_index] == 2 and 'not' not in line) or (key[key_index] == 2 and '^' not in line):\n",
    "                    pass\n",
    "                else:\n",
    "                    pdb.set_trace()\n",
    "                    \n",
    "key_line_num = search_key_lines('mnist_DTLock_Some_XOR_XNOR.py')\n",
    "for i,line_num in enumerate(key_line_num):\n",
    "    write_line_file('mnist_DTLock_Some_XOR_XNOR.py', i, line_num)\n",
    "correct_keygate_xor_xnor('mnist_DTLock_Some_XOR_XNOR.py', key)\n",
    "\n",
    "#Performing final inspection\n",
    "inspect_keygate_xor_xnor('mnist_DTLock_Some_XOR_XNOR.py', key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Verify the accuracy by using this dumped decision rules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct key: 0.8167 0.82926\n"
     ]
    }
   ],
   "source": [
    "from mnist_DTLock_Some_XOR_XNOR import dtLOCKED_Some_XOR_XNOR\n",
    "y_test_pred_tree = []\n",
    "for i,test_samples in enumerate(X_test):\n",
    "    y_test_pred_tree.append(dtLOCKED_Some_XOR_XNOR(test_samples,key))\n",
    "\n",
    "y_train_pred_tree = []\n",
    "for i,test_samples in enumerate(X_train):\n",
    "    y_train_pred_tree.append(dtLOCKED_Some_XOR_XNOR(test_samples,key))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Correct key:',accuracy_score(y_test, y_test_pred_tree), accuracy_score(y_train, y_train_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Verify the accuracy by using this dumped decision rules with incorrect key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incorrect key: 0.2237 0.22138\n"
     ]
    }
   ],
   "source": [
    "incorrect_key=key.copy()\n",
    "y_test_pred_tree = []\n",
    "#shuffle the key list to simulate incorrect key\n",
    "np.random.shuffle(incorrect_key)\n",
    "for i,test_samples in enumerate(X_test):\n",
    "    y_test_pred_tree.append(dtLOCKED_Some_XOR_XNOR(test_samples,incorrect_key))\n",
    "\n",
    "y_train_pred_tree = []\n",
    "for i,test_samples in enumerate(X_train):\n",
    "    y_train_pred_tree.append(dtLOCKED_Some_XOR_XNOR(test_samples,incorrect_key))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "print('Incorrect key:',accuracy_score(y_test, y_test_pred_tree), accuracy_score(y_train, y_train_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sequential Circuit HDL: FSM Generator   (Run this cell twice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "from sklearn.tree import _tree\n",
    "\n",
    "def tree_to_code(tree, feature_names):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "    \n",
    "    def recurse(node, depth):\n",
    "        indent = \"  \" * depth\n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            print (\"{}{}:if (({} <= {}) && (({} <= {}) ^ key)==({} <= {})) \".format(indent, node, name, int(round(threshold,3)), name, int(round(threshold,3)), name, int(round(threshold,3)))) \n",
    "            recurse(tree_.children_left[node], depth + 1)\n",
    "            print (\"{}{}:else \".format(indent, node, name, int(round(threshold,3))))\n",
    "            recurse(tree_.children_right[node], depth + 1)\n",
    "        else:\n",
    "            print (\"{} Label<={};\".format(indent, np.argmax(tree_.value[node][0],axis=0)))\n",
    "\n",
    "    recurse(0, 1)\n",
    "\n",
    "cols = range(784)\n",
    "features = ['pixels[{}]'.format(str(i)) for i in cols]\n",
    "class_names = [str(i) for i in dt_clf.classes_]\n",
    "tree_to_code(dt_clf, features)\n",
    "\n",
    "with open('verilog_newFSM.txt', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "def write_file(data_towrite):\n",
    "    with open('verilog_file_somenode_XOR_XNOR.v', 'a', encoding='utf-8') as file:\n",
    "        file.writelines(data_towrite)\n",
    "        file.close()\n",
    "        \n",
    "def write_line_file(data_towrite, line_num):\n",
    "    with open('verilog_file_somenode_XOR_XNOR.v', 'r', encoding='utf-8') as file:\n",
    "        file_content = file.readlines()\n",
    "        file.close()\n",
    "    file_content[line_num] = file_content[line_num].replace('\\n','') + ' ' + data_towrite + '\\n'  \n",
    "    with open('verilog_file_somenode_XOR_XNOR.v', 'w', encoding='utf-8') as file:\n",
    "        file.writelines(file_content)\n",
    "        file.close()\n",
    "        \n",
    "def search_content_file(word):\n",
    "    with open('verilog_file_somenode_XOR_XNOR.v', 'r') as file:\n",
    "        file_content = file.readlines()\n",
    "        for line_num,line in enumerate(file_content):\n",
    "            if word in line:\n",
    "                return(line_num)\n",
    "        return(\"content doesn't exists.\")\n",
    "    \n",
    "def update_stateformat_file():\n",
    "    with open('verilog_file_somenode_XOR_XNOR.v', 'r', encoding='utf-8') as file:\n",
    "        file_content = file.readlines()\n",
    "        file.close()\n",
    "    for line_num,line in enumerate(file_content):\n",
    "        if 'if' in line:\n",
    "            file_content[line_num] = '16\\'d' + file_content[line_num].strip() + ' \\n'  \n",
    "    with open('verilog_file_somenode_XOR_XNOR.v', 'w', encoding='utf-8') as file:\n",
    "        file.writelines(file_content)\n",
    "        file.close()\n",
    "        \n",
    "def clear_file():\n",
    "    with open('verilog_file_somenode_XOR_XNOR.v', 'w', encoding='utf-8') as file:\n",
    "        pass\n",
    "        file.close()\n",
    "\n",
    "import itertools\n",
    "with open('verilog_newFSM.txt', 'r') as f:\n",
    "    tree_verilog = f.read()\n",
    "    f.close()\n",
    "\n",
    "clear_file()\n",
    "line_num = 0\n",
    "else_state = 0\n",
    "else_nextif_state = 0\n",
    "curr_line,next_line = itertools.tee(tree_verilog.split('\\n'))\n",
    "next(next_line, None)\n",
    "for i,j in list(zip(curr_line,next_line)):\n",
    "    if 'Label' in i:\n",
    "        pass\n",
    "        #write_file(f'  begin {i.strip()} state<=0;ml_inference_completed<=1; end \\n')\n",
    "    elif 'else' in i and 'Label' in j:\n",
    "        else_state = i.strip().split(':')[0]\n",
    "        line_num = search_content_file(' '+str(else_state)+':if' )\n",
    "        write_line_file(f'\\n       else begin {j.strip()} state<=0;ml_inference_completed<=1; end ', line_num)\n",
    "        #write_file(f'   {i.strip().split(\":\")[-1]} ')\n",
    "    elif 'else' in i and 'if' in j:\n",
    "        else_state = i.strip().split(':')[0]\n",
    "        else_nextif_state = j.strip().split(':')[0]\n",
    "        line_num = search_content_file(' '+str(else_state)+':if' )\n",
    "        write_line_file(f'else begin state<={else_nextif_state}; end ', line_num)\n",
    "    elif 'if' in i and 'Label' in j:\n",
    "        write_file(f'\\n {i.strip()} begin {j.strip()} state<=0;ml_inference_completed<=1; end ')\n",
    "    elif 'if' in i and 'if' in j:\n",
    "        write_file(f'\\n {i.strip()} begin state<={j.strip().split(\":\")[0]}; end \\n ')  \n",
    "update_stateformat_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('verilog_file_somenode_XOR_XNOR.v', 'r', encoding='utf-8') as file:\n",
    "    file_content = file.readlines()\n",
    "    file.close()\n",
    "\n",
    "key_index = 0\n",
    "for line_num,line in enumerate(file_content):\n",
    "    if 'key' in line:\n",
    "        file_content[line_num] = file_content[line_num].replace('key',f'key[{key_index}]')\n",
    "        if key[key_index]==1: file_content[line_num] = file_content[line_num].replace('^','~^')\n",
    "        if key[key_index]==2: file_content[line_num] = file_content[line_num].split('&&')[0]+')' + file_content[line_num].split('))')[1] + '\\n'\n",
    "        key_index = key_index+1\n",
    "with open('verilog_file_somenode_XOR_XNOR.v', 'w', encoding='utf-8') as file:\n",
    "        file.writelines(file_content)\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### This should go into verilog.\n",
    "\n",
    "While sending the key to the FPGA replace all the 2 with either 1 or 0 because such value at that position in the key regsiter is not read during inferencing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg [251:0] key;\n",
      "initial key = {1'b1, 1'b1, 1'b0, 1'b0, 1'b1, 1'b1, 1'b1, 1'b0, 1'b0, 1'b0, 1'b1, 1'b0, 1'b0, 1'b1, 1'b1, 1'b1, 1'b1, 1'b1, 1'b0, 1'b1, 1'b0, 1'b1, 1'b1, 1'b0, 1'b1, 1'b1, 1'b0, 1'b1, 1'b0, 1'b0, 1'b0, 1'b0, 1'b1, 1'b0, 1'b0, 1'b1, 1'b1, 1'b1, 1'b1, 1'b0, 1'b0, 1'b0, 1'b0, 1'b0, 1'b1, 1'b1, 1'b1, 1'b0, 1'b1, 1'b0, 1'b1, 1'b1, 1'b1, 1'b0, 1'b0, 1'b1, 1'b1, 1'b1, 1'b0, 1'b1, 1'b1, 1'b0, 1'b1, 1'b0, 1'b0, 1'b0, 1'b1, 1'b1, 1'b0, 1'b1, 1'b0, 1'b0, 1'b1, 1'b1, 1'b0, 1'b0, 1'b0, 1'b1, 1'b1, 1'b1, 1'b1, 1'b1, 1'b1, 1'b0, 1'b1, 1'b0, 1'b0, 1'b0, 1'b1, 1'b0, 1'b0, 1'b1, 1'b0, 1'b0, 1'b0, 1'b0, 1'b1, 1'b0, 1'b0, 1'b0, 1'b1, 1'b1, 1'b1, 1'b1, 1'b1, 1'b1, 1'b0, 1'b0, 1'b1, 1'b0, 1'b1, 1'b1, 1'b1, 1'b0, 1'b1, 1'b0, 1'b0, 1'b0, 1'b1, 1'b1, 1'b1, 1'b0, 1'b0, 1'b1, 1'b1, 1'b1, 1'b0, 1'b0, 1'b1, 1'b1, 1'b1, 1'b1, 1'b0, 1'b1, 1'b0, 1'b1, 1'b1, 1'b0, 1'b0, 1'b1, 1'b1, 1'b1, 1'b1, 1'b1, 1'b0, 1'b0, 1'b1, 1'b0, 1'b1, 1'b1, 1'b1, 1'b1, 1'b0, 1'b0, 1'b0, 1'b0, 1'b1, 1'b0, 1'b0, 1'b0, 1'b1, 1'b1, 1'b1, 1'b0, 1'b0, 1'b0, 1'b1, 1'b1, 1'b0, 1'b1, 1'b0, 1'b1, 1'b0, 1'b1, 1'b1, 1'b1, 1'b1, 1'b0, 1'b0, 1'b1, 1'b1, 1'b0, 1'b1, 1'b1, 1'b1, 1'b0, 1'b1, 1'b1, 1'b0, 1'b0, 1'b1, 1'b0, 1'b0, 1'b1, 1'b1, 1'b0, 1'b1, 1'b1, 1'b0, 1'b0, 1'b1, 1'b1, 1'b1, 1'b0, 1'b0, 1'b1, 1'b1, 1'b1, 1'b1, 1'b1, 1'b1, 1'b1, 1'b1, 1'b1, 1'b1, 1'b0, 1'b0, 1'b1, 1'b1, 1'b1, 1'b1, 1'b0, 1'b1, 1'b1, 1'b1, 1'b1, 1'b1, 1'b0, 1'b1, 1'b0, 1'b1, 1'b1, 1'b1, 1'b0, 1'b1, 1'b1, 1'b1, 1'b0, 1'b1, 1'b1, 1'b0, 1'b1, 1'b0, 1'b0, 1'b0, 1'b0, 1'b1, 1'b1, 1'b1, 1'b1, 1'b1, 1'b0};\n"
     ]
    }
   ],
   "source": [
    "#print([int(i) for i in list(''.join([str(i) for i in key]).replace('2',str(np.random.randint(0,2))))])\n",
    "reverse_order_key = key.copy()\n",
    "reverse_order_key = list(reverse_order_key)\n",
    "reverse_order_key.reverse()\n",
    "#reversing the order because in verilog the leftmost is MSB (key[counter_if]) and rightmost is LSB key[0].\n",
    "print(f'reg [{counter_if-1}:0] key;')\n",
    "display_string = f'initial key = '+ '{' + \", \".join([\"1'b\"+str(x) for x in reverse_order_key]).replace(\"2\",str(np.random.randint(0,2))) + '}'\n",
    "print(display_string+';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
